import {
  VideoObjectDetectionSetting
} from "@/components/Dashboard/widgets/video-object-detection/VideoObjectDetectionSetting.tsx"
import {
  type StreamStats,
  type VideoData,
  getInitialStreamStats,
  getInitialVideoData,
} from "@/dashboard/store/media-channel-store/video-store"
import {VideoStoreManager} from "@/dashboard/store/media-channel-store/video-store-manager.ts"
import {Box, Flex, IconButton} from "@chakra-ui/react"
import * as cocoSsd from "@tensorflow-models/coco-ssd"
import * as tf from "@tensorflow/tfjs"
import type React from "react"
import {useCallback} from "react"
import {useEffect, useRef, useState} from "react"
import {WidgetFrame} from "../WidgetFrame"

interface Detection {
  class: string
  score: number
  bbox: [number, number, number, number]
}

export interface VideoObjectDetectionWidgetConfig {
  stream_id: string
  tf_model: string
}

interface VideoObjectDetectionWidgetProps {
  robotId: string
  config: VideoObjectDetectionWidgetConfig
  onUpdateConfig?: (newConfig: VideoObjectDetectionWidgetConfig) => void
  setOpenSetting?: (openSetting: boolean) => void
  onRemove?: () => void
}

interface ErrorWidgetProps extends VideoObjectDetectionWidgetProps {
  openSetting: boolean
  message: string
}

const ErrorWidget: React.FC<ErrorWidgetProps> = ({
                                                   robotId,
                                                   config,
                                                   onUpdateConfig,
                                                   openSetting,
                                                   setOpenSetting,
                                                   onRemove,
                                                   message,
                                                 }) => (
  <>
    <WidgetFrame
      title="Video Object Detection"
      robot_id={robotId}
      isConnected={false}
      footerMessage={message}
      onSettingClick={() => {
        setOpenSetting?.(true)
      }}
      onRemove={onRemove}
    >
      <Flex
        direction="column"
        align="center"
        justify="center"
        h="100%"
        color="red.500"
        textAlign="center"
      >
        <Box fontSize="2xl" mb={2}>
          ‚ö†Ô∏è
        </Box>
        <Box fontSize="sm">{message}</Box>
      </Flex>
    </WidgetFrame>
    {openSetting && (
      <VideoObjectDetectionSetting
        isOpen={openSetting}
        config={config}
        onUpdateConfig={onUpdateConfig}
        onClose={() => {
          setOpenSetting?.(false)
        }}
      />
    )}
  </>
)

export const VideoObjectDetectionWidget: React.FC<
  VideoObjectDetectionWidgetProps
> = ({robotId, config, onUpdateConfig, onRemove}) => {
  const videoStoreManager = VideoStoreManager.getInstance()

  const [openSetting, setOpenSetting] = useState(false)
  const videoRef = useRef<HTMLVideoElement>(null)
  const canvasRef = useRef<HTMLCanvasElement>(null)
  const [videoData, setVideoData] = useState<VideoData | null>(
    getInitialVideoData(),
  )
  const [streamStats, setStreamStats] = useState<StreamStats>(
    getInitialStreamStats(),
  )
  const [isPlaying, setIsPlaying] = useState(false)
  const [error, setError] = useState<string | null>(null)
  const [isConnected, setIsConnected] = useState(false)

  // Object Detection Í¥ÄÎ†® ÏÉÅÌÉú
  const [model, setModel] = useState<any>(null)
  const [isModelLoading, setIsModelLoading] = useState(true)
  const [isDetecting, setIsDetecting] = useState(false)
  const [detections, setDetections] = useState<Detection[]>([])
  const animationFrameRef = useRef<number | null>(null)

  const store = videoStoreManager.createVideoStoreByMediaTypeAuto(
    robotId,
    config?.stream_id,
  )

  // TensorFlow.js Ï¥àÍ∏∞Ìôî Î∞è Î™®Îç∏ Î°úÎìú
  useEffect(() => {
    const initializeTensorFlow = async () => {
      try {
        setIsModelLoading(true)

        // TensorFlow.js Î∞±ÏóîÎìú Ï¥àÍ∏∞Ìôî
        await tf.ready()
        console.log("‚úÖ TensorFlow.js ready")

        // COCO-SSD Î™®Îç∏ Î°úÎìú
        const loadedModel = await cocoSsd.load()
        setModel(loadedModel)
        setIsModelLoading(false)
        console.log("‚úÖ COCO-SSD model loaded successfully")
      } catch (err) {
        console.error("‚ùå TensorFlow initialization failed:", err)
        setError("Failed to initialize TensorFlow.js or load model")
        setIsModelLoading(false)
      }
    }

    initializeTensorFlow()
  }, [])

  // Ï∫îÎ≤ÑÏä§ ÏÑ§Ï†ï
  const setupCanvas = useCallback(() => {
    if (videoRef.current && canvasRef.current) {
      const canvas = canvasRef.current
      const video = videoRef.current

      // videoÏùò Ïã§Ï†ú ÎπÑÎîîÏò§ ÌÅ¨Í∏∞
      const videoWidth = video.videoWidth
      const videoHeight = video.videoHeight

      // video elementÏùò display ÌÅ¨Í∏∞
      const elementWidth = video.offsetWidth
      const elementHeight = video.offsetHeight

      // object-fit: containÏúºÎ°ú Ïù∏Ìïú Ïã§Ï†ú ÌëúÏãú ÏòÅÏó≠ Í≥ÑÏÇ∞
      const videoAspectRatio = videoWidth / videoHeight
      const elementAspectRatio = elementWidth / elementHeight

      let displayWidth: number
      let displayHeight: number
      let offsetX: number
      let offsetY: number

      if (videoAspectRatio > elementAspectRatio) {
        // ÎπÑÎîîÏò§Í∞Ä Îçî ÎÑìÏùå - Í∞ÄÎ°úÍ∞Ä ÍΩâ Ï∞∏
        displayWidth = elementWidth
        displayHeight = elementWidth / videoAspectRatio
        offsetX = 0
        offsetY = (elementHeight - displayHeight) / 2
      } else {
        // ÎπÑÎîîÏò§Í∞Ä Îçî ÎÜíÏùå - ÏÑ∏Î°úÍ∞Ä ÍΩâ Ï∞∏
        displayWidth = elementHeight * videoAspectRatio
        displayHeight = elementHeight
        offsetX = (elementWidth - displayWidth) / 2
        offsetY = 0
      }

      // Ï∫îÎ≤ÑÏä§ ÌÅ¨Í∏∞Î•º Ïã§Ï†ú ÎπÑÎîîÏò§ Ìï¥ÏÉÅÎèÑÎ°ú ÏÑ§Ï†ï
      canvas.width = videoWidth
      canvas.height = videoHeight

      // Ï∫îÎ≤ÑÏä§ Ïä§ÌÉÄÏùºÏùÑ Ïã§Ï†ú ÌëúÏãú ÏòÅÏó≠Ïóê ÎßûÍ≤å ÏÑ§Ï†ï
      canvas.style.width = `${displayWidth}px`
      canvas.style.height = `${displayHeight}px`
      canvas.style.position = "absolute"
      canvas.style.top = `${offsetY + 12}px`
      canvas.style.left = `${offsetX + 12}px`
    }
  }, [])

  const nextFrame = () => {
    animationFrameRef.current = requestAnimationFrame(() => {
      setTimeout(detectObjects, 100)
    })
  }

  // Í∞ùÏ≤¥ ÌÉêÏßÄ
  const detectObjects = useCallback(async () => {
    if (!isDetecting || !model || !videoRef.current || !canvasRef.current) {
      nextFrame()
      return
    }

    try {
      const video = videoRef.current
      const canvas = canvasRef.current
      const ctx = canvas.getContext("2d")

      if (!ctx || video.readyState !== 4) {
        // Îã§Ïùå ÌîÑÎ†àÏûÑÏóêÏÑú Ïû¨ÏãúÎèÑ
        nextFrame()
        return
      }

      // Í∞ùÏ≤¥ ÌÉêÏßÄ ÏàòÌñâ
      const predictions = await model.detect(video)

      // ÌÉêÏßÄ Í≤∞Í≥º ÌïÑÌÑ∞ÎßÅ Î∞è Î≥ÄÌôò (ÌÉÄÏûÖ ÏïàÏ†ÑÏÑ± ÌôïÎ≥¥)
      const filteredDetections: Detection[] = predictions
        .filter((prediction: cocoSsd.DetectedObject) => prediction.score > 0.5)
        .map((prediction: cocoSsd.DetectedObject) => ({
          class: prediction.class,
          score: prediction.score,
          bbox: prediction.bbox,
        }))

      setDetections(filteredDetections)

      // Ï∫îÎ≤ÑÏä§ ÌÅ¥Î¶¨Ïñ¥
      ctx.clearRect(0, 0, canvas.width, canvas.height)
      setupCanvas()

      drawDetections(ctx, filteredDetections)
    } catch (err) {
      console.error("Detection error:", err)
    }

    // Îã§Ïùå ÌîÑÎ†àÏûÑ Ïä§ÏºÄÏ§ÑÎßÅ (10FPS)
    if (isDetecting && isPlaying) {
      nextFrame()
    }
  }, [isDetecting, isPlaying, model])

  // ÌÉêÏßÄ Í≤∞Í≥º Í∑∏Î¶¨Í∏∞
  const drawDetections = (
    ctx: CanvasRenderingContext2D,
    detections: Detection[],
  ) => {
    ctx.strokeStyle = "#00ff00"
    ctx.lineWidth = 3
    ctx.font = "35px Arial"
    ctx.fillStyle = "#00ff00"
    ctx.shadowColor = "rgba(0, 0, 0, 0.5)"
    ctx.shadowOffsetX = 1
    ctx.shadowOffsetY = 1

    detections.forEach((detection) => {
      const [x, y, width, height] = detection.bbox

      // Î∞îÏö¥Îî© Î∞ïÏä§ Í∑∏Î¶¨Í∏∞
      ctx.strokeRect(x, y, width, height)

      // ÎùºÎ≤®Í≥º Ïã†Î¢∞ÎèÑ Í∑∏Î¶¨Í∏∞
      const label = `${detection.class} ${(detection.score * 100).toFixed(1)}%`
      const textWidth = ctx.measureText(label).width
      const textHeight = 35

      const padding = 5
      const backgroundHeight = textHeight + padding * 2

      // Î∞∞Í≤Ω ÏÇ¨Í∞ÅÌòï
      ctx.fillStyle = "rgba(0, 255, 0, 0.8)"
      ctx.fillRect(
        x,
        y - backgroundHeight,
        textWidth + padding * 2,
        backgroundHeight,
      )

      // ÌÖçÏä§Ìä∏
      ctx.fillStyle = "#000000"
      ctx.shadowColor = "transparent"
      ctx.fillText(label, x + padding, y - padding)
      ctx.shadowColor = "rgba(0, 0, 0, 0.5)"
    })
  }

  // ÌÉêÏßÄ ÏûêÎèô ÏãúÏûë
  useEffect(() => {
    if (model && isConnected) {
      setIsDetecting(true)
      // detectObjects Ìò∏Ï∂úÏùÑ Îã§Ïùå Î†åÎçîÎßÅ ÏÇ¨Ïù¥ÌÅ¥Î°ú ÏßÄÏó∞
      const timer = setTimeout(detectObjects, 0)
      return () => clearTimeout(timer)
    }
    setIsDetecting(false)
    if (animationFrameRef.current) {
      cancelAnimationFrame(animationFrameRef.current)
      animationFrameRef.current = null
    }
    // Ï∫îÎ≤ÑÏä§ ÌÅ¥Î¶¨Ïñ¥
    if (canvasRef.current) {
      const ctx = canvasRef.current.getContext("2d")
      ctx?.clearRect(0, 0, canvasRef.current.width, canvasRef.current.height)
    }
    setDetections([])
  }, [model, isConnected, detectObjects])

  const configureVideo = () => {
    if (!store) {
      return () => {
      }
    }

    // ÎπÑÎîîÏò§ ÏóòÎ¶¨Î®ºÌä∏ ÏÑ§Ï†ï
    if (videoRef.current) {
      store.setVideoElement(videoRef.current)
    }

    // MediaStream ÏÉÅÌÉú ÌôïÏù∏
    const mediaStream = store.getMediaStream()

    if (mediaStream) {
      // MediaStreamÏù¥ ÎπÑÎîîÏò§ ÏóòÎ¶¨Î®ºÌä∏Ïóê Ïó∞Í≤∞ÎêòÏóàÎäîÏßÄ ÌôïÏù∏
      if (videoRef.current && videoRef.current.srcObject === mediaStream) {
        // MediaStreamÏù¥ Ïó∞Í≤∞ÎêòÎ©¥ ÏûêÎèô Ïû¨ÏÉù ÏãúÎèÑ
        if (videoRef.current.paused) {
          videoRef.current.play().catch((error) => {
            console.error("‚ùå ÎπÑÎîîÏò§ ÏûêÎèô Ïû¨ÏÉù Ïã§Ìå®:", error)
          })
        }
      }
    }

    // ÎπÑÎîîÏò§ Ïù¥Î≤§Ìä∏ Ìï∏Îì§Îü¨
    const videoElement = videoRef.current
    if (videoElement) {
      const handlePlay = () => {
        setIsPlaying(true)
      }
      const handlePause = () => {
        setIsPlaying(false)
      }
      const handleLoadedMetadata = () => {
        setError(null)
        setupCanvas()
      }
      const handleError = (e: any) => {
        console.error("ÎπÑÎîîÏò§ Î°úÎìú Ïò§Î•ò:", e)
        setError("ÎπÑÎîîÏò§ Î°úÎìú Ï§ë Ïò§Î•òÍ∞Ä Î∞úÏÉùÌñàÏäµÎãàÎã§.")
      }

      videoElement.addEventListener("play", handlePlay)
      videoElement.addEventListener("pause", handlePause)
      videoElement.addEventListener("loadedmetadata", handleLoadedMetadata)
      videoElement.addEventListener("error", handleError)

      return () => {
        videoElement.removeEventListener("play", handlePlay)
        videoElement.removeEventListener("pause", handlePause)
        videoElement.removeEventListener("loadedmetadata", handleLoadedMetadata)
        videoElement.removeEventListener("error", handleError)
      }
    }

    return () => {
      // ÎπÑÎîîÏò§ ÏóòÎ¶¨Î®ºÌä∏Í∞Ä Î≥ÄÍ≤ΩÎêòÎ©¥ Ïù¥Ï†Ñ Ïù¥Î≤§Ìä∏ Ìï∏Îì§Îü¨ Ï†úÍ±∞
      if (videoRef.current) {
        videoRef.current.srcObject = null
      }
    }
  }

  useEffect(() => {
    if (!store) return

    const unsubscribe = store.subscribe((data) => {
      setVideoData(data)
      setIsConnected(data.isActive)
      setError(null)
      if (data.isActive) {
        configureVideo()
      }
    })

    const unscribeStreamStats = store.subscribeStreamStats((stats) => {
      setStreamStats(stats)
    })

    // Ï¥àÍ∏∞ Îç∞Ïù¥ÌÑ∞ ÏÑ§Ï†ï
    if (store.getMediaStream()) {
      const initialData: VideoData = {
        streamId: store.getMediaStream()?.id || "",
        robotId: store.getRobotId(),
        channelLabel: store.getChannelLabel(),
        mediaStream: store.getMediaStream()!,
        isActive: store.isStreamActive(),
        timestamp: Date.now(),
      }
      setVideoData(initialData)
      setIsConnected(store.isStreamActive())
    }

    const closing = configureVideo()

    return () => {
      closing()
      unsubscribe()
      unscribeStreamStats()
    }
  }, [store, videoRef.current])

  const handlePlayPause = () => {
    if (videoRef.current) {
      if (isPlaying) {
        videoRef.current.pause()
      } else {
        videoRef.current.play()
      }
    }
  }

  if (!config || !config.stream_id) {
    return (
      <ErrorWidget
        robotId={robotId}
        config={config}
        onUpdateConfig={onUpdateConfig}
        openSetting={openSetting}
        setOpenSetting={setOpenSetting}
        onRemove={onRemove}
        message={"No stream ID configured"}
      />
    )
  }

  if (!store) {
    return (
      <ErrorWidget
        robotId={robotId}
        config={config}
        onUpdateConfig={onUpdateConfig}
        openSetting={openSetting}
        setOpenSetting={setOpenSetting}
        onRemove={onRemove}
        message={"No video stream available"}
      />
    )
  }

  // Footer info
  const footerInfo =
    videoData && streamStats
      ? [
        {
          label: "FPS",
          value: `${streamStats.fps} fps`,
        },
        {
          label: "Stream ID",
          value: videoData.streamId,
        },
        {
          label: "Model",
          value: config.tf_model,
        },
      ]
      : []

  const getStatusMessage = () => {
    if (isModelLoading) return "Loading AI model..."
    if (!isConnected) return "Waiting for stream..."
    if (isDetecting) return `Detecting objects... (${detections.length} found)`
    return "Video stream active"
  }

  return (
    <>
      <WidgetFrame
        title="Video Object Detection"
        robot_id={robotId}
        isConnected={isConnected}
        footerInfo={footerInfo}
        footerMessage={getStatusMessage()}
        onSettingClick={() => {
          setOpenSetting?.(true)
        }}
        onRemove={onRemove}
      >
        {error ? (
          <Flex
            direction="column"
            align="center"
            justify="center"
            h="100%"
            color="red.500"
            textAlign="center"
          >
            <Box fontSize="2xl" mb={2}>
              ‚ö†Ô∏è
            </Box>
            <Box fontSize="sm">{error}</Box>
          </Flex>
        ) : (
          <>
            <video
              ref={videoRef}
              style={{
                width: "100%",
                height: "100%",
                objectFit: "contain",
                borderRadius: "8px",
              }}
              playsInline
              muted
              autoPlay
            />

            {/* Object Detection Canvas Overlay */}
            <canvas
              ref={canvasRef}
              style={{
                position: "absolute",
                top: 0,
                left: 0,
                pointerEvents: "none",
                borderRadius: "8px",
              }}
            />

            {/* ÎπÑÎîîÏò§ Ïª®Ìä∏Î°§ Ïò§Î≤ÑÎ†àÏù¥ */}
            <Box
              position="absolute"
              bottom={0}
              left={0}
              right={0}
              bg="linear-gradient(to top, rgba(0,0,0,0.7), transparent)"
              p={3}
              opacity={0}
              _hover={{opacity: 1}}
              transition="opacity 0.2s"
            >
              <Flex justify="center" align="center" gap={2}>
                <IconButton
                  size="sm"
                  colorScheme="whiteAlpha"
                  onClick={handlePlayPause}
                  aria-label={isPlaying ? "Pause" : "Play"}
                >
                  {isPlaying ? "‚è∏Ô∏è" : "‚ñ∂Ô∏è"}
                </IconButton>
              </Flex>
            </Box>

            {/* Î™®Îç∏ Î°úÎî© Ïù∏ÎîîÏºÄÏù¥ÌÑ∞ */}
            {isModelLoading && (
              <Flex
                position="absolute"
                top={0}
                left={0}
                right={0}
                bottom={0}
                bg="rgba(0, 0, 0, 0.5)"
                align="center"
                justify="center"
                color="white"
              >
                <Box textAlign="center">
                  <Box fontSize="2xl" mb={2}>
                    ü§ñ
                  </Box>
                  <Box fontSize="sm">Loading AI model...</Box>
                </Box>
              </Flex>
            )}
          </>
        )}
      </WidgetFrame>
      {openSetting && (
        <VideoObjectDetectionSetting
          isOpen={openSetting}
          config={config}
          onUpdateConfig={onUpdateConfig}
          onClose={() => {
            setOpenSetting?.(false)
          }}
        />
      )}
    </>
  )
}
